<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="hadoop,hive,spark" />
   
  <meta name="description" content="try everything!" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Hadoop单节点安装部署 |  大数据学习笔记
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    <main class="content on">
      <section class="outer">
  <article id="post-Hadoop/Hadoop单节点安装部署" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Hadoop单节点安装部署
</h1>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2017/05/01/Hadoop/Hadoop%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/" class="article-date">
  <time datetime="2017-05-01T02:00:00.000Z" itemprop="datePublished">2017-05-01</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

      
      
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.5k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">12 分钟</span>
        </span>
    </span>
</div>

      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="Hadoop单节点安装部署"><a href="#Hadoop单节点安装部署" class="headerlink" title="Hadoop单节点安装部署"></a>Hadoop单节点安装部署</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在这一章节中，我们主要学习如何快速安装与配置单节点的Hadoop，以便使用HDFS和MapReduce快速执行简单操作。</p>
<h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><h3 id="支持平台"><a href="#支持平台" class="headerlink" title="支持平台"></a>支持平台</h3><ul>
<li>建议Linux。</li>
</ul>
<h3 id="所需软件"><a href="#所需软件" class="headerlink" title="所需软件"></a>所需软件</h3><ul>
<li>JDK（建议JDK1.8）</li>
<li>如果要使用可选的启动和停止脚本，则必须安装ssh并保证sshd一直运行，以便Hadoop 脚本管理远程Hadoop守护进程。此外，为了更好地管理ssh资源，建议安装pdsh。</li>
</ul>
<h3 id="安装软件"><a href="#安装软件" class="headerlink" title="安装软件"></a>安装软件</h3><p>安装上面所需的软件，这里主要是jdk的安装配置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 创建文件夹</span></span><br><span class="line">[root@node01 opt]<span class="comment"># mkdir /usr/java</span></span><br><span class="line"><span class="comment">## 解压到指定文件夹</span></span><br><span class="line">[root@node01 opt]<span class="comment"># tar -zxvf jdk-8u162-linux-x64.tar.gz-C /usr/java/</span></span><br><span class="line"><span class="comment">## 修正所属用户及用户组</span></span><br><span class="line">[root@node01 opt]<span class="comment"># cd /usr/java</span></span><br><span class="line">[root@node01 opt]<span class="comment"># chown -R root:root /usr/java/jdk1.8.0_162/</span></span><br><span class="line"><span class="comment">## 配置Java环境变量，末尾追加</span></span><br><span class="line">[root@node01 opt]<span class="comment"># vim /etc/profile</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_162</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment">## 使配置生效并查看</span></span><br><span class="line">[root@node01 opt]<span class="comment"># source /etc/profile</span></span><br><span class="line">[root@node01 java]<span class="comment"># which java</span></span><br><span class="line">/usr/java/jdk1.8.0_162/bin/java</span><br><span class="line">[root@node01 java]<span class="comment"># java -version</span></span><br><span class="line">java version <span class="string">"1.8.0_162"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_162-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)</span><br><span class="line"><span class="comment">## 默认情况下，ssh已经安装。这里不再单独处理。</span></span><br><span class="line">[root@node01 opt]<span class="comment"># which ssh</span></span><br><span class="line">/usr/bin/ssh</span><br><span class="line">[root@node01 opt]<span class="comment"># which sshd</span></span><br><span class="line">/usr/sbin/sshd</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop版本选择"><a href="#Hadoop版本选择" class="headerlink" title="Hadoop版本选择"></a>Hadoop版本选择</h2><p><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" target="_blank" rel="noopener">官网下载</a>Hadoop稳定发行版本，解压缩到指定目录。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@master opt]<span class="comment"># tar -zxvf hadoop-3.2.1</span></span><br><span class="line"><span class="comment">## 解压之后的文件目录如下</span></span><br><span class="line">[root@node01 opt]<span class="comment"># ll hadoop-3.2.1</span></span><br><span class="line">drwxr-xr-x. 2 1001 1001    203 Sep 11  2019 bin</span><br><span class="line">drwxr-xr-x. 3 1001 1001     20 Sep 10  2019 etc</span><br><span class="line">drwxr-xr-x. 2 1001 1001    106 Sep 11  2019 include</span><br><span class="line">drwxr-xr-x. 3 1001 1001     20 Sep 11  2019 lib</span><br><span class="line">drwxr-xr-x. 4 1001 1001    288 Sep 11  2019 libexec</span><br><span class="line">-rw-rw-r--. 1 1001 1001 150569 Sep 10  2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 1001 1001  22125 Sep 10  2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 1001 1001   1361 Sep 10  2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 1001 1001   4096 Sep 10  2019 sbin</span><br><span class="line">drwxr-xr-x. 4 1001 1001     31 Sep 11  2019 share</span><br></pre></td></tr></table></figure>
<h2 id="运行Hadoop集群的准备工作"><a href="#运行Hadoop集群的准备工作" class="headerlink" title="运行Hadoop集群的准备工作"></a>运行Hadoop集群的准备工作</h2><p>运行Hadoop集群之前，需要先编辑<code>etc/hadoop/hadoop-env.sh</code>文件，设置<code>JAVA_HOME</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 设置JAVA_HOME</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># vim etc/hadoop/hadoop-env.sh </span></span><br><span class="line"><span class="comment"># Technically, the only required environment variable is JAVA_HOME.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_162</span><br><span class="line"><span class="comment">## 将会显示hadoop 脚本的使用文档，这里截取部分内容展示</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hadoop</span></span><br><span class="line">...</span><br><span class="line">archive       create a Hadoop archive</span><br><span class="line">checknative   check native Hadoop and compression libraries availability</span><br><span class="line">classpath     prints the class path needed to get the Hadoop jar and the required libraries</span><br><span class="line">conftest      validate configuration XML files</span><br><span class="line">credential    interact with credential providers</span><br><span class="line">distch        distributed metadata changer</span><br><span class="line">distcp        copy file or directories recursively</span><br><span class="line">dtutil        operations related to delegation tokens</span><br><span class="line">envvars       display computed Hadoop environment variables</span><br><span class="line">fs            run a generic filesystem user client</span><br><span class="line">gridmix       submit a mix of synthetic job, modeling a profiled from production load</span><br><span class="line">jar &lt;jar&gt;     run a jar file. NOTE: please use <span class="string">"yarn jar"</span> to launch YARN applications, not this <span class="built_in">command</span>.</span><br></pre></td></tr></table></figure>

<p>现在可以使用以下三种支持的模式中的一种来启动Hadoop集群：</p>
<ul>
<li>Local (Standalone) Mode：单机模式</li>
<li>Pseudo-Distributed Mode：伪分布式模式</li>
<li>Fully-Distributed Mode：完全分布式模式</li>
</ul>
<h2 id="单机模式的操作方法"><a href="#单机模式的操作方法" class="headerlink" title="单机模式的操作方法"></a>单机模式的操作方法</h2><p>默认情况下，Hadoop被配置成以非分布式模式运行的一个独立Java进程。这对调试非常有帮助。（换句话来说，单机模式通常用于调试）<br>下面的实例是将已解压的 conf 目录拷贝作为输入，查找并显示匹配给定正则表达式的条目。输出写入到指定的output目录。 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># mkdir input</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># cp etc/hadoop/*.xml input</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+'</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># cat output/*</span></span><br><span class="line">1	dfsadmin</span><br><span class="line"><span class="comment">## 注意：在执行过程中我们可以新开一个窗口查看Java进程</span></span><br><span class="line">[root@node01 ~]<span class="comment"># jps</span></span><br><span class="line">11157 RunJar</span><br><span class="line">11205 Jps</span><br></pre></td></tr></table></figure>
<h2 id="伪分布式模式的操作方法"><a href="#伪分布式模式的操作方法" class="headerlink" title="伪分布式模式的操作方法"></a>伪分布式模式的操作方法</h2><p>Hadoop可以在单节点上以所谓的伪分布式模式运行，此时每一个Hadoop守护进程都作为一个独立的Java进程运行。</p>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>这里主要是修改下面两个配置文件</p>
<ul>
<li>etc/hadoop/core-site.xml</li>
<li>etc/hadoop/hdfs-site.xml</li>
</ul>
<h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--core-site.xml配置文件新增NameNode的URI---&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- NameNode的URI--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--设置副本数，这里是单节点，只能有1个副本--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="免密码ssh设置"><a href="#免密码ssh设置" class="headerlink" title="免密码ssh设置"></a>免密码ssh设置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 首先检查一下是否可以免密登录到localhost</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># ssh localhost</span></span><br><span class="line"><span class="comment">## The authenticity of host 'localhost (::1)' can't be established.</span></span><br><span class="line"><span class="comment">## 如果不能，进行免密ssh设置</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment">#  ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment">#  cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># chmod 0600 ~/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure>
<h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>以下的用法是在本地运行MR作业。<br>如果想要在YARN上执行作业，参考<strong>YARN on Single Node</strong>。</p>
<ol>
<li><p>格式化一个新的分布式文件系统</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs namenode -format</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动NameNode和DataNode守护进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 注意：这是如果使用的是Hadoop3.x版本，需要先修改sbin/start-dfs.sh和sbin/stop-dfs.sh脚本文件，不然会报错，错误如下：</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/start-dfs.sh</span></span><br><span class="line">Starting namenodes on [localhost]</span><br><span class="line">ERROR: Attempting to operate on hdfs namenode as root</span><br><span class="line">ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.</span><br><span class="line">Starting datanodes</span><br><span class="line">ERROR: Attempting to operate on hdfs datanode as root</span><br><span class="line">ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.</span><br><span class="line">Starting secondary namenodes [node01]</span><br><span class="line">ERROR: Attempting to operate on hdfs secondarynamenode as root</span><br><span class="line">ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.</span><br><span class="line"><span class="comment">## 修改sbin/start-dfs.sh和sbin/stop-dfs.sh脚本文件，新增配置参数如下</span></span><br><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="comment">## 脚本文件修改之后再次启动</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/start-dfs.sh</span></span><br><span class="line"><span class="comment">##启动成功之后可以查看当前守护进程</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># jps</span></span><br><span class="line">12100 SecondaryNameNode</span><br><span class="line">11862 DataNode</span><br><span class="line">11722 NameNode</span><br><span class="line">12222 Jps</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问NameNode的Web界面<br>NameNode -<a href="http://localhost:9870/" target="_blank" rel="noopener">http://localhost:9870/</a><br>注意：<strong>如果选用的是Hadoop3.x以下的版本，默认的端口号应该是50070</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 如果NameNode节点正常启动，但是无法访问，考虑是否开启了防火墙，需要保证防火墙是关闭的</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># systemctl status firewalld</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>新建执行MapReduce作业所需的HDFS目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -mkdir /user</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -mkdir /user/root</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>拷贝测试文件到HDFS上指定目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -mkdir input</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -ls </span></span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2020-06-06 19:56 input</span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -put etc/hadoop/*.xml input</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]# bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.1.jar grep input output &#39;dfs[a-z.]+&#39;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看运行结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 我们可以选择从HDFS上拷贝到Linux之后查看结果</span></span><br><span class="line"><span class="comment">## 我们先删除指点单机模式下的output文件，避免冲突</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># rm -rf output/</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -get output output</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># cat output/*</span></span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line"><span class="comment">##或者直接通过HDFS命令查看运行结果</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -cat output/*</span></span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line"><span class="comment">##注意：这里与之前单节点模式数据结果不一致是因为我们配置伪分布式模式的时候修改了配置文件</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>停止守护进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/stop-dfs.sh</span></span><br><span class="line"><span class="comment">## 停止之后查看进程</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># jps</span></span><br><span class="line">13835 Jps</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="YARN-on-Single-Node"><a href="#YARN-on-Single-Node" class="headerlink" title="YARN on Single Node"></a>YARN on Single Node</h3><p>通过设置几个参数并另外运行ResourceManager守护进程和NodeManager守护进程，以伪分布式模式在YARN上运行MapReduce作业。<br>基于上面伪分布式模式1-4步的配置，这里我们额外新增其它配置信息。</p>
<ol>
<li><p>修改配置文件，主要是下面两个配置文件：etc/hadoop/mapred-site.xml和etc/hadoop/yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--mapred-site.xml配置文件新增--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--etc/hadoop/yarn-site.xml配置文件新增--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动ResourceManager 和NodeManager守护进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 注意：如果是基于Hadoop3.x版本，我们需要先修改sbin/start-yarn.sh 和sbin/stop-yarn.sh脚本文件，否则会报错，错误如下：</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/start-yarn.sh </span></span><br><span class="line">Starting resourcemanager</span><br><span class="line">ERROR: Attempting to operate on yarn resourcemanager as root</span><br><span class="line">ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.</span><br><span class="line">Starting nodemanagers</span><br><span class="line">ERROR: Attempting to operate on yarn nodemanager as root</span><br><span class="line">ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.</span><br><span class="line"><span class="comment">## 修改sbin/start-yarn.sh 和sbin/stop-yarn.sh脚本文件，新增下列参数</span></span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br><span class="line"><span class="comment">## 重新启动</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/start-yarn.sh </span></span><br><span class="line"><span class="comment">## 启动完成之后查看Java进程</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># jps</span></span><br><span class="line">14931 ResourceManager</span><br><span class="line">15397 Jps</span><br><span class="line">14310 DataNode</span><br><span class="line">15064 NodeManager</span><br><span class="line">14158 NameNode</span><br><span class="line">14542 SecondaryNameNode</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问ResourceManager的Web界面<br>ResourceManager -<a href="http://localhost:8088/" target="_blank" rel="noopener">http://localhost:8088/</a></p>
</li>
<li><p>执行MapReduce作业</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 注意：这里需要先删除之前生成的output文件夹，不然会报错:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/output already exists</span></span><br><span class="line"><span class="comment">## 先删除之前生成的output文件夹</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -rm -r output/</span></span><br><span class="line">Deleted output</span><br><span class="line"><span class="comment">## 执行MapReduce作业</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+'</span></span><br><span class="line"><span class="comment">## 查看执行结果</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># bin/hdfs dfs -cat output/*</span></span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br></pre></td></tr></table></figure>
</li>
<li><p>完成全部操作后，停止守护进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 关闭yarn相关的守护进程</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/stop-yarn.sh </span></span><br><span class="line"><span class="comment">## 关闭hdfs相关的守护进程</span></span><br><span class="line">[root@node01 hadoop-3.2.1]<span class="comment"># sbin/stop-dfs.sh</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这一章节中，我们主要学习了如何在单节点上部署Hadoop的单机模式和伪分布式模式，并运行简单的MapReduce作业。需要注意的是：单机模式是在本地运行MR作业，而伪分布式模式既可以在本地运行MR作业，也可以在YARN上运行MR作业。</p>

      
      <!-- reward -->
      
      <div id="reward-btn">
        打赏
      </div>
      
    </div>
    
    
      <!-- copyright -->
      
        <div class="declare">
          <ul class="post-copyright">
            <li>
              <i class="ri-copyright-line"></i>
              <strong>版权声明： </strong>
              本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
            </li>
          </ul>
        </div>
        
    <footer class="article-footer">
      
          
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://yoursite.com/2017/05/01/Hadoop/Hadoop%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/" rel="tag">Hadoop入门学习</a></li></ul>


    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2017/05/04/Hadoop/Hadoop%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Hadoop常用Shell命令
          
        </div>
      </a>
    
    
      <a href="/2017/01/01/Other/Hexo%E6%90%AD%E5%BB%BAGitHub%E5%8D%9A%E5%AE%A2%E5%92%8CGitee%E5%8D%9A%E5%AE%A2/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Hexo搭建GitHub博客和Gitee博客</div>
      </a>
    
  </nav>


  

  

  
  
  
  
  

</article>
</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2020
        <i class="ri-heart-fill heart_icon"></i> henrrywan
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 <a href="https://hexo.io" target="_blank">Hexo</a> 强力驱动
        <span class="division">|</span>
        主题 - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="大数据学习笔记"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>





<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>



<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>





<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>

  
<script src="/js/clickLove.js"></script>



<!-- 复制 -->

  
<link rel="stylesheet" href="/css/clipboard.css">

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




    
  </div>
</body>

</html>